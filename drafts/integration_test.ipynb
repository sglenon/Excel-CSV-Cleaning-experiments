{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9606a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import openai\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "import xlwings as xw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981b642",
   "metadata": {},
   "source": [
    "# Loading of Data-Only Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9163ea",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_excel = xw.App(visible=False) \n",
    "input_file = r\"C:\\Users\\CSD Admin\\OneDrive - DOST-ASTI\\Kevin\\CODING\\CSV_Excel_Cleaning\\data\\test_sheet_by_department.xlsx\"\n",
    "wbk = app_excel.books.open(input_file)\n",
    "wbk.api.RefreshAll()\n",
    "wbk.save(input_file)\n",
    "wbk.close()\n",
    "app_excel.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5eea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_data = openpyxl.load_workbook(input_file, data_only=True)\n",
    "ws = wb_data.active\n",
    "df = pd.DataFrame(ws.values)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeee7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as temp_file:\n",
    "#    temp_path = temp_file.name\n",
    "temp_path = r\"C:\\Users\\CSD Admin\\OneDrive - DOST-ASTI\\Kevin\\CODING\\CSV_Excel_Cleaning\\results\\temp_file.xlsx\"\n",
    "input_1 = input_file\n",
    "output_evaluated = evaluate_formulas_in_excel(input_1, temp_path)\n",
    "df = pd.read_excel(temp_path)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d2c95",
   "metadata": {},
   "source": [
    "# Defining Table Boundaries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e2c9c",
   "metadata": {},
   "source": [
    "## Loading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59010a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"--- CRITICAL ERROR: OpenAI API key not found. Please set the OPENAI_API_KEY environment variable. ---\")\n",
    "    sys.exit(1)\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from src.script_a_find_table_boundaries import find_table_boundaries\n",
    "    from src.script_b_process_with_pandas import process_table_with_pandas\n",
    "except ImportError as e:\n",
    "    print(f\"Error: Could not import necessary functions. Make sure all script files are in the same directory.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002d8ce",
   "metadata": {},
   "source": [
    "## find_table_boundaries function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_table_boundaries(file_path: str, output_json_path: str):\n",
    "    \"\"\"\n",
    "    Uses pandas to read the original file and AI to find the precise table boundaries.\n",
    "    \"\"\"\n",
    "    print(\"--- Step A: Finding Table Boundaries using Pandas ---\")\n",
    "    try:\n",
    "        # Read the file with pandas, forcing everything to string for the AI analysis text.\n",
    "        # This prevents any data loss during this initial inspection step.\n",
    "        df = pd.read_excel(file_path, header=None, sheet_name=0, dtype=str)\n",
    "        df_string = df.to_string(index=True, header=False)\n",
    "\n",
    "        prompt = (\n",
    "            \"You are an expert data analyst. Below is text from an Excel sheet. \"\n",
    "            \"Your task is to find the boundaries of the main data table.\\n\\n\"\n",
    "            \"1.  **header_start_index**: Find the row index where the main column headers begin. This row contains 'DEPARTMENT', 'NCA RELEASES', etc. The index is the number on the far left.\\n\"\n",
    "            \"2.  **data_end_index**: Find the row index of the last row of actual data (the last department/agency). This is the row just before the footnotes (which start with '/1 Source...').\\n\\n\"\n",
    "            \"Respond with ONLY a JSON object containing these two keys. For example: {\\\"header_start_index\\\": 4, \\\"data_end_index\\\": 52}\"\n",
    "        )\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt}, {\"role\": \"user\", \"content\": df_string}],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        boundaries = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        if 'header_start_index' not in boundaries or 'data_end_index' not in boundaries:\n",
    "            raise ValueError(\"AI response did not contain the required keys.\")\n",
    "\n",
    "        print(f\"  [AI] Identified header start: {boundaries['header_start_index']}, data end: {boundaries['data_end_index']}\")\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(boundaries, f, indent=4)\n",
    "        print(f\"  [AI] Table boundaries saved to '{output_json_path}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] An error occurred in Script A: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7dd45",
   "metadata": {},
   "source": [
    "## Running function on input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "input_excel_file = r\"C:\\Users\\CSD Admin\\OneDrive - DOST-ASTI\\Kevin\\CODING\\CSV_Excel_Cleaning\\test_sheet_by_department.xlsx\"\n",
    "output_directory = r\"C:\\Users\\CSD Admin\\OneDrive - DOST-ASTI\\Kevin\\CODING\\CSV_Excel_Cleaning\\results\"\n",
    "\n",
    "input_path = Path(input_excel_file)\n",
    "output_dir = Path(output_directory)\n",
    "\n",
    "if not input_path.is_file():\n",
    "    raise FileNotFoundError(f\"Error: Input file not found at '{input_path}'\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define paths\n",
    "boundaries_json = output_dir / \"table_boundaries.json\"\n",
    "final_excel_path = output_dir / (input_path.stem + \"_processed.xlsx\")\n",
    "final_csv_path = output_dir / (input_path.stem + \"_processed.csv\")\n",
    "\n",
    "# to run, uv run main_script.py test.xlsx output_folder\n",
    "\n",
    "step_a_results = find_table_boundaries(str(input_path), str(boundaries_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635caa5",
   "metadata": {},
   "source": [
    "# Processing with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "HEADER_ROW_COUNT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load Boundaries and the ORIGINAL Data with Pandas ---\n",
    "boundaries_json_path = r\"C:\\Users\\CSD Admin\\OneDrive - DOST-ASTI\\Kevin\\CODING\\CSV_Excel_Cleaning\\results\\table_boundaries.json\"\n",
    "\n",
    "with open(boundaries_json_path, 'r') as f:\n",
    "    boundaries = json.load(f)\n",
    "header_start = boundaries['header_start_index']\n",
    "data_end = boundaries['data_end_index']\n",
    "\n",
    "# Read the ORIGINAL file. Let pandas infer data types; it's designed to read formula values.\n",
    "# This is the most reliable way to get the numeric data.\n",
    "df = pd.read_excel(input_path, header=None, sheet_name=0)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  [Read] Successfully loaded original Excel file into memory.\")\n",
    "# --- Step 2: Slice and Process ---\n",
    "table_df = df.iloc[header_start : data_end + 1].copy()\n",
    "print(f\"  [Slice] Extracted table from row {header_start} to {data_end}.\")\n",
    "header_df = table_df.iloc[:HEADER_ROW_COUNT].copy()\n",
    "data_df = table_df.iloc[HEADER_ROW_COUNT:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_df.ffill(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67756ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns_raw = []\n",
    "for col_idx in range(header_df.shape[1]):\n",
    "    levels = [str(header_df.iloc[row_idx, col_idx]) for row_idx in range(HEADER_ROW_COUNT)]\n",
    "    cleaned_levels = [lvl.split('/')[0].strip() for lvl in levels if 'unnamed' not in lvl.lower() and lvl.lower() != 'nan']\n",
    "    new_name = '_'.join(cleaned_levels).replace(' ', '_').replace('%_of', 'pct_of').lower()\n",
    "    if new_name == 'department_department': new_name = 'department'\n",
    "    new_columns_raw.append(new_name)\n",
    "\n",
    "final_columns = []\n",
    "counts = defaultdict(int)\n",
    "for name in new_columns_raw:\n",
    "    counts[name] += 1\n",
    "    if counts[name] > 1: final_columns.append(f\"{name}_{counts[name]-1}\")\n",
    "    else: final_columns.append(name)\n",
    "print(\"  [Clean] Headers have been refactored and de-duplicated.\")\n",
    "print(final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns = final_columns\n",
    "first_col = data_df.columns[0]\n",
    "data_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.rename(columns={first_col: 'department'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[~data_df['department'].astype(str).str.contains('TOTAL|DEPARTMENTS', case=False, na=False)]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_df.dropna(how='all', inplace=True)\n",
    "data_df.reset_index(drop=True, inplace=True)\n",
    "data_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_excel(final_excel_path, index=False)\n",
    "print(f\"  [Save] Final clean Excel file generated at '{final_excel_path}'\")\n",
    "data_df.to_csv(final_csv_path, index=False)\n",
    "print(f\"  [Save] Final clean CSV file generated at '{final_csv_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
